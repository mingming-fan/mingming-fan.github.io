<!doctype html><html lang=zh-Hans><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=stylesheet href=../../../css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=../../../css/wowchemy.b9231f75dcc97a371ce6141b4d2aadaf.css><link rel=stylesheet href=../../../css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=../../../css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Mingming Fan"><meta name=description content="Recent advances on the Internet of Things (IoT) lead to an explosion of physical objects being connected to the Internet. These objects sense, compute, interpret what is occurring within themselves and the world, and preferably interact with users. In this work, we present a visible light-enabled finger tracking technique allowing users to perform freestyle multi-touch gestures on everyday object’s surface. By projecting encoded patterns onto an object’s surface (e.g. paper, display, or table) through a projector, and localizing the user’s fingers with light sensors, the proposed system offers users a richer interactive space than the device’s existing interfaces. More importantly, results from our experiments indicate that this system can localize ten fingers simultaneously with an accuracy of 1.7 mm and an refresh rate of 84 Hz with only 31 ms delay on WiFi or 23 ms delay on serial communication, easily supporting multi-finger gesture interaction on everyday objects. We also develop two example applications to demonstrate possible scenarios. Finally, we conduct a preliminary exploration of 3D depth inference using the same setup and achieve 2.43 cm depth estimation accuracy."><link rel=alternate hreflang=en href=../../../publication/3d-finger-tracking/><link rel=alternate hreflang=zh-Hans href=../../../zh/publication/3d-finger-tracking/><link rel=canonical href=../../../zh/publication/3d-finger-tracking/><link rel=manifest href=../../../zh/manifest.webmanifest><link rel=icon type=image/png href=../../../media/icon_hu9a55cf1972a19f5af2e1cfae94af68a2_11598_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=../../../media/icon_hu9a55cf1972a19f5af2e1cfae94af68a2_11598_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@wowchemy"><meta property="twitter:creator" content="@wowchemy"><meta property="twitter:image" content="/zh/publication/3d-finger-tracking/featured.jpg"><meta property="og:site_name" content="APEX, HKUST(GZ) & HKUST"><meta property="og:url" content="/zh/publication/3d-finger-tracking/"><meta property="og:title" content="Projected Visible Light for 3D Finger Tracking and Device Augmentation on Everyday Objects | APEX, HKUST(GZ) & HKUST"><meta property="og:description" content="Recent advances on the Internet of Things (IoT) lead to an explosion of physical objects being connected to the Internet. These objects sense, compute, interpret what is occurring within themselves and the world, and preferably interact with users. In this work, we present a visible light-enabled finger tracking technique allowing users to perform freestyle multi-touch gestures on everyday object’s surface. By projecting encoded patterns onto an object’s surface (e.g. paper, display, or table) through a projector, and localizing the user’s fingers with light sensors, the proposed system offers users a richer interactive space than the device’s existing interfaces. More importantly, results from our experiments indicate that this system can localize ten fingers simultaneously with an accuracy of 1.7 mm and an refresh rate of 84 Hz with only 31 ms delay on WiFi or 23 ms delay on serial communication, easily supporting multi-finger gesture interaction on everyday objects. We also develop two example applications to demonstrate possible scenarios. Finally, we conduct a preliminary exploration of 3D depth inference using the same setup and achieve 2.43 cm depth estimation accuracy."><meta property="og:image" content="/zh/publication/3d-finger-tracking/featured.jpg"><meta property="og:locale" content="zh-Hans"><meta property="article:published_time" content="2019-04-24T00:00:00+00:00"><meta property="article:modified_time" content="2019-04-24T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"/zh/publication/3d-finger-tracking/"},"headline":"Projected Visible Light for 3D Finger Tracking and Device Augmentation on Everyday Objects","image":["/zh/publication/3d-finger-tracking/featured.jpg"],"datePublished":"2019-04-24T00:00:00Z","dateModified":"2019-04-24T00:00:00Z","author":{"@type":"Person","name":"Shang Ma"},"publisher":{"@type":"Organization","name":"APEX, HKUST(GZ) \u0026 HKUST","logo":{"@type":"ImageObject","url":"/media/logo_hub0d66fecfb75d04d26dd973adb7e184d_88470_192x192_fit_lanczos_3.png"}},"description":"Recent advances on the Internet of Things (IoT) lead to an explosion of physical objects being connected to the Internet. These objects sense, compute, interpret what is occurring within themselves and the world, and preferably interact with users. In this work, we present a visible light-enabled finger tracking technique allowing users to perform freestyle multi-touch gestures on everyday object’s surface. By projecting encoded patterns onto an object’s surface (e.g. paper, display, or table) through a projector, and localizing the user’s fingers with light sensors, the proposed system offers users a richer interactive space than the device’s existing interfaces. More importantly, results from our experiments indicate that this system can localize ten fingers simultaneously with an accuracy of 1.7 mm and an refresh rate of 84 Hz with only 31 ms delay on WiFi or 23 ms delay on serial communication, easily supporting multi-finger gesture interaction on everyday objects. We also develop two example applications to demonstrate possible scenarios. Finally, we conduct a preliminary exploration of 3D depth inference using the same setup and achieve 2.43 cm depth estimation accuracy."}</script><title>Projected Visible Light for 3D Finger Tracking and Device Augmentation on Everyday Objects | APEX, HKUST(GZ) & HKUST</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=0e57527ef1bdf58ef5b4fb0d5ff88fa2><script src=../../../js/wowchemy-init.min.fe8634e7d00f14d07fb33caf14cc8e55.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>搜索</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=搜索... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=搜索...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=../../../zh/><img src=../../../media/logo_hub0d66fecfb75d04d26dd973adb7e184d_88470_0x70_resize_lanczos_3.png alt="APEX, HKUST(GZ) & HKUST"></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label=切换导航>
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=../../../zh/><img src=../../../media/logo_hub0d66fecfb75d04d26dd973adb7e184d_88470_0x70_resize_lanczos_3.png alt="APEX, HKUST(GZ) & HKUST"></a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=../../../zh/#about><span>关于</span></a></li><li class=nav-item><a class=nav-link href=../../../zh/people><span>团队</span></a></li><li class=nav-item><a class=nav-link href=../../../zh/publication><span>出版物</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=搜索><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown i18n-dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true aria-label=语言><i class="fas fa-globe mr-1" aria-hidden=true></i><span class="d-none d-lg-inline">中文 (简体)</span></a><div class=dropdown-menu><div class="dropdown-item dropdown-item-active"><span>中文 (简体)</span></div><a class=dropdown-item href=../../../publication/3d-finger-tracking/><span>English</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>Projected Visible Light for 3D Finger Tracking and Device Augmentation on Everyday Objects</h1><div class=article-metadata><div><span><a href=../../../zh/author/shang-ma/>Shang Ma</a></span>, <span><a href=../../../zh/author/qiong-liu/>Qiong Liu</a></span>, <span><a href=../../../zh/author/mingming-fan/>Mingming Fan</a></span>, <span><a href=../../../zh/author/phillip-sheu/>Phillip Sheu</a></span></div><span class=article-date>四月 2019</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=https://www.mingmingfan.com/papers/InternetOfThings-2019-Ma.pdf target=_blank rel=noopener>PDF</a></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:230px><div style=position:relative><img src=../../../zh/publication/3d-finger-tracking/featured_hucd5912b10ccd2d3eb25559d9b2c88ec8_614288_720x2500_fit_q75_h2_lanczos.webp width=720 height=230 alt class=featured-image></div></div><div class=article-container><h3>摘要</h3><p class=pub-abstract>Recent advances on the Internet of Things (IoT) lead to an explosion of physical objects being connected to the Internet. These objects sense, compute, interpret what is occurring within themselves and the world, and preferably interact with users. In this work, we present a visible light-enabled finger tracking technique allowing users to perform freestyle multi-touch gestures on everyday object’s surface. By projecting encoded patterns onto an object’s surface (e.g. paper, display, or table) through a projector, and localizing the user’s fingers with light sensors, the proposed system offers users a richer interactive space than the device’s existing interfaces. More importantly, results from our experiments indicate that this system can localize ten fingers simultaneously with an accuracy of 1.7 mm and an refresh rate of 84 Hz with only 31 ms delay on WiFi or 23 ms delay on serial communication, easily supporting multi-finger gesture interaction on everyday objects. We also develop two example applications to demonstrate possible scenarios. Finally, we conduct a preliminary exploration of 3D depth inference using the same setup and achieve 2.43 cm depth estimation accuracy.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">类型</div><div class="col-12 col-md-9"><a href=../../../zh/publication/#6>Sensing</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">出版物</div><div class="col-12 col-md-9">Internet of Things. 2019. Volume 6. Elsevier</div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=../../../zh/tag/coded-visible-light/>Coded visible light</a>
<a class="badge badge-light" href=../../../zh/tag/finger-tracking/>Finger tracking</a>
<a class="badge badge-light" href=../../../zh/tag/projector-based-interaction/>Projector-based interaction</a>
<a class="badge badge-light" href=../../../zh/tag/object-augmentation/>Object augmentation</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=%2Fzh%2Fpublication%2F3d-finger-tracking%2F&amp;text=Projected+Visible+Light+for+3D+Finger+Tracking+and+Device+Augmentation+on+Everyday+Objects" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=%2Fzh%2Fpublication%2F3d-finger-tracking%2F&amp;t=Projected+Visible+Light+for+3D+Finger+Tracking+and+Device+Augmentation+on+Everyday+Objects" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Projected%20Visible%20Light%20for%203D%20Finger%20Tracking%20and%20Device%20Augmentation%20on%20Everyday%20Objects&amp;body=%2Fzh%2Fpublication%2F3d-finger-tracking%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=%2Fzh%2Fpublication%2F3d-finger-tracking%2F&amp;title=Projected+Visible+Light+for+3D+Finger+Tracking+and+Device+Augmentation+on+Everyday+Objects" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Projected+Visible+Light+for+3D+Finger+Tracking+and+Device+Augmentation+on+Everyday+Objects%20%2Fzh%2Fpublication%2F3d-finger-tracking%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=%2Fzh%2Fpublication%2F3d-finger-tracking%2F&amp;title=Projected+Visible+Light+for+3D+Finger+Tracking+and+Device+Augmentation+on+Everyday+Objects" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2023 APEX Group. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>由<a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a>支持发布——免费<a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>开源</a>网站，为创作者赋能。</p></footer></div></div><script src=../../../js/vendor-bundle.min.b4708d4364577c16ab7001b265a063a4.js></script><script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":true}</script><script src=../../../js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script><script src=../../../zh/js/wowchemy.min.d06bc4b307d61ec1811f19928b741e02.js></script><script src=../../../js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>引用</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> 复制
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> 下载</a><div id=modal-error></div></div></div></div></div><script src=../../../js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>
<!doctype html><html lang=zh-hans><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=stylesheet href=../css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=../css/wowchemy.b9231f75dcc97a371ce6141b4d2aadaf.css><link rel=stylesheet href=../css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=../css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Mingming Fan"><meta name=description content="A highly-customizable Hugo research group theme powered by Wowchemy website builder."><link rel=alternate hreflang=en href=../><link rel=alternate hreflang=zh-hans href=../zh/><link rel=canonical href=../zh/><link rel=manifest href=../zh/manifest.webmanifest><link rel=icon type=image/png href=../media/icon_hu9a55cf1972a19f5af2e1cfae94af68a2_11598_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=../media/icon_hu9a55cf1972a19f5af2e1cfae94af68a2_11598_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@wowchemy"><meta property="twitter:creator" content="@wowchemy"><meta property="twitter:image" content="/media/logo_hub0d66fecfb75d04d26dd973adb7e184d_88470_300x300_fit_lanczos_3.png"><meta property="og:site_name" content="APEX, HKUST(GZ) & HKUST"><meta property="og:url" content="/zh/"><meta property="og:title" content="APEX, HKUST(GZ) & HKUST"><meta property="og:description" content="A highly-customizable Hugo research group theme powered by Wowchemy website builder."><meta property="og:image" content="/media/logo_hub0d66fecfb75d04d26dd973adb7e184d_88470_300x300_fit_lanczos_3.png"><meta property="og:locale" content="zh-Hans"><meta property="og:updated_time" content="2023-03-04T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","potentialAction":{"@type":"SearchAction","target":"/?q={search_term_string}","query-input":"required name=search_term_string"},"url":"/"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","@id":"/","name":"APEX, HKUST(GZ) \u0026 HKUST","logo":"/media/logo_hub0d66fecfb75d04d26dd973adb7e184d_88470_192x192_fit_lanczos_3.png","url":"/"}</script><script src=https://identity.netlify.com/v1/netlify-identity-widget.js></script>
<link rel=alternate href=../zh/index.xml type=application/rss+xml title="APEX, HKUST(GZ) & HKUST"><title>APEX, HKUST(GZ) & HKUST</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper><script src=../js/wowchemy-init.min.fe8634e7d00f14d07fb33caf14cc8e55.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>搜索</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=搜索... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=搜索...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=../zh/><img src=../media/logo_hub0d66fecfb75d04d26dd973adb7e184d_88470_0x70_resize_lanczos_3.png alt="APEX, HKUST(GZ) & HKUST"></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label=切换导航>
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=../zh/><img src=../media/logo_hub0d66fecfb75d04d26dd973adb7e184d_88470_0x70_resize_lanczos_3.png alt="APEX, HKUST(GZ) & HKUST"></a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=../zh/#about data-target=#about><span>关于</span></a></li><li class=nav-item><a class=nav-link href=../zh/people><span>团队</span></a></li><li class=nav-item><a class=nav-link href=../zh/publication><span>出版物</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=搜索><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown i18n-dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true aria-label=语言><i class="fas fa-globe mr-1" aria-hidden=true></i><span class="d-none d-lg-inline">中文 (简体)</span></a><div class=dropdown-menu><div class="dropdown-item dropdown-item-active"><span>中文 (简体)</span></div><a class=dropdown-item href=../ data-target=/><span>English</span></a></div></li></ul></div></nav></header></div><div class=page-body><span class="js-widget-page d-none"></span><section id=welcome class="home-section wg-blank"><div class=home-section-bg></div><div class=container><div class="row justify-content-center"><div class="section-heading col-12 mb-3 text-center"><h1 class=mb-0><strong>A</strong>ccessible & <strong>P</strong>ervasive User <strong>EX</strong>perience<br>(APEX) Group</h1></div><div class=col-12><br><div style=text-align:center><strong>让计算机技术更加普及和易用</strong></div><br><p>只有当计算机技术对每个人都是可及且易用时，它才会赋予人们更多的力量。否则，计算机技术的进步将只惠及那些有特权获得它的人，从而导致网络世界不平等的加剧。因此，我们现在面临的一个挑战是：如何让计算机技术更加普及和易用，让每个人都能受益？</p><p>欢迎来到 APEX 研究组！在<a href=https://www.mingmingfan.com/ target=_blank rel=noopener>范明明教授</a>的带领下，我们从以下三个方面着手解决这一问题：</p><ul><li><p>了解<strong>无障碍问题</strong>，并创建新颖的<strong>辅助技术</strong>，特别针对为 <em>老年人</em> 和 <em>残障人士</em> 服务；</p></li><li><p>探索新的<strong>计算用户体验（UX）方法</strong>，通过将人类智慧与计算相结合，从而更好地检测、理解和解决 UX 问题；</p></li><li><p>通过创建多感官体验和新的交互技术，使<strong>虚拟现实 VR/增强现实 AR/元宇宙 Metaverse</strong>更易于访问。</p></li></ul><p>APEX 研究组的研究成果在人机交互（HCI）和无障碍领域的顶级会议，如 ACM CHI、ACM UbiComp 和 ACM ASSETS 等会议上，荣获了最佳论文奖、最佳论文提名奖和最佳工件奖。</p><img src=../home/QR.jpeg width=50% style=margin-left:auto;margin-right:auto;align:center><div style=display:flex;justify-content:center><div style=margin:20px><ul class=cta-group><li><a href=./people/ class="btn btn-primary px-3 py-3">团队 →</a></li></ul></div></div></div></div></div></section><section id=news class="home-section wg-pages"><div class=home-section-bg></div><div class=container><div class="row justify-content-center"><div class="section-heading col-12 mb-3 text-center"><h1 class=mb-0>Latest News</h1></div><div class=col-12><div class="card-simple view-card"><div class=article-metadata><span class=article-date>1月 14, 2023</span>
<span class=middot-divider></span>
<span class=article-reading-time>1 分钟阅读时长</span></div><a href=../zh/post/chi2023/><div class=img-hover-zoom><img src=../zh/post/chi2023/featured_hu795383ad64dc15f176bbc1cdd22b5a51_252461_808x455_fill_q75_h2_lanczos_smart1_3.webp height=455 width=808 class=article-banner alt="七篇长论文被 CHI 2023 录用" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=../zh/post/chi2023/>七篇长论文被 CHI 2023 录用</a></div><a href=../zh/post/chi2023/ class=summary-link><div class=article-style><p><p>APEX人机交互团队的七篇论文被 <a href=https://chi2023.acm.org/ target=_blank rel=noopener>ACM CHI 2023</a>, 人机交互领域的顶级会议录用！</p></p></div></a></div></div></div></div></section><section id=featured class="home-section wg-featured"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Featured Publications</h1></div><div class="col-12 col-lg-8"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/tvcg-2023-uxsense/>uxSense: Supporting User Experience Analysis with Visualization and Computer Vision</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/andrea-batch/>Andrea Batch</a></span>, <span><a href=../zh/author/yipeng-ji/>Yipeng Ji</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span>, <span><a href=../zh/author/jian-zhao/>Jian Zhao</a></span>, <span><a href=../zh/author/niklas-elmqvist/>Niklas Elmqvist</a></span></div><span class=article-date>三月 2023</span>
<span class=middot-divider></span>
<span class=pub-publication>TVCG 2023</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/TVCG_uxSense.pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1109/TVCG.2023.3241581 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=../zh/publication/tvcg-2023-uxsense/><img src=../zh/publication/tvcg-2023-uxsense/featured_hu73197f1111d73663912e0ff0526d2f03_1208447_150x0_resize_q75_h2_lanczos_3.webp height=82 width=150 alt="uxSense: Supporting User Experience Analysis with Visualization and Computer Vision" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/chi23-copractter/>CoPracTter: Toward Integrating Personalized Practice Scenarios, Timely Feedback and Social Support into An Online Support Tool for Coping with Stuttering in China</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/li-feng/>Li Feng</a></span>, <span><a href=../zh/author/zeyu-xiong/>Zeyu Xiong</a></span>, <span><a href=../zh/author/xinyi-li/>Xinyi Li</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span></div><span class=article-date>二月 2023</span>
<span class=middot-divider></span>
<span class=pub-publication>CHI 2023</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/CHI23-CoPractTer.pdf target=_blank rel=noopener>PDF</a></div></div><div class=ml-3><a href=../zh/publication/chi23-copractter/><img src=../zh/publication/chi23-copractter/featured_hu63eaf26345d82d4e3c76c08f565ac722_6442030_150x0_resize_q75_h2_lanczos.webp height=61 width=150 alt="CoPracTter: Toward Integrating Personalized Practice Scenarios, Timely Feedback and Social Support into An Online Support Tool for Coping with Stuttering in China" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/chi23-vr-intergenerational-gap/>Bridging the Generational Gap : Exploring How Virtual Reality Supports Remote Communication Between Grandparents and Grandchildren</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/xiaoying-wei/>Xiaoying Wei</a></span>, <span><a href=../zh/author/yizheng-gu/>Yizheng Gu</a></span>, <span><a href=../zh/author/emily-kuang/>Emily Kuang</a></span>, <span><a href=../zh/author/xian-wang/>Xian Wang</a></span>, <span><a href=../zh/author/beiyan-cao/>Beiyan Cao</a></span>, <span><a href=../zh/author/xiaofu-jin/>Xiaofu Jin</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i></div><span class=article-date>二月 2023</span>
<span class=middot-divider></span>
<span class=pub-publication>CHI 2023</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/CHI23-bridge-gap.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/zh/publication/chi23-vr-intergenerational-gap/cite.bib>引用</a></div></div><div class=ml-3><a href=../zh/publication/chi23-vr-intergenerational-gap/><img src=../zh/publication/chi23-vr-intergenerational-gap/featured_hu8e3acd7b452b1579ef464d2de134b32b_1925300_150x0_resize_q75_h2_lanczos.webp height=80 width=150 alt="Bridging the Generational Gap : Exploring How Virtual Reality Supports Remote Communication Between Grandparents and Grandchildren" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/chi23-oa-typing/>Enhancing Older Adults’ Gesture Typing Experience Using the T9 Keyboard on Small Touchscreen Devices</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/emily-kuang/>Emily Kuang</a></span>, <span><a href=../zh/author/ruihuan-chen/>Ruihuan Chen</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i></div><span class=article-date>二月 2023</span>
<span class=middot-divider></span>
<span class=pub-publication>CHI 2023</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/CHI23_OA_Gesture_Typing_T9.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/zh/publication/chi23-oa-typing/cite.bib>引用</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1145/3544548.3581105 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=../zh/publication/chi23-oa-typing/><img src=../zh/publication/chi23-oa-typing/featured_hu281c0878955817726fab0276a47d20cc_2022324_150x0_resize_q75_h2_lanczos_3.webp height=49 width=150 alt="Enhancing Older Adults’ Gesture Typing Experience Using the T9 Keyboard on Small Touchscreen Devices" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/chi23-ux-conversational-ai-assistant/>Collaboration with Conversational AI Assistants for UX Evaluation: Questions and How to Ask them (Voice vs. Text)</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/emily-kuang/>Emily Kuang</a></span>, <span><a href=../zh/author/ehsan-jahangirzadeh-soure/>Ehsan Jahangirzadeh Soure</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i>, <span><a href=../zh/author/jian-zhao/>Jian Zhao</a></span>, <span><a href=../zh/author/kristen-shinohara/>Kristen Shinohara</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i></div><span class=article-date>二月 2023</span>
<span class=middot-divider></span>
<span class=pub-publication>CHI 2023</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/CHI23_UX_Design_Probe.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/zh/publication/chi23-ux-conversational-ai-assistant/cite.bib>引用</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1145/3544548.3581247 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=../zh/publication/chi23-ux-conversational-ai-assistant/><img src=../zh/publication/chi23-ux-conversational-ai-assistant/featured_hu2ded00ce85048d122b739fa6c894a05a_871191_150x0_resize_q75_h2_lanczos_3.webp height=68 width=150 alt="Collaboration with Conversational AI Assistants for UX Evaluation: Questions and How to Ask them (Voice vs. Text)" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/chi23-dhh-livestreaming/>Sparkling Silence: Practices and Challenges of Livestreaming Among Deaf or Hard of Hearing Streamers</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/beiyan-cao/>Beiyan Cao</a></span>, <span><a href=../zh/author/changyang-he/>Changyang He</a></span>, <span><a href=../zh/author/muzhi-zhou/>Muzhi Zhou</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i></div><span class=article-date>二月 2023</span>
<span class=middot-divider></span>
<span class=pub-publication>CHI 2023</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/CHI23-DHH-livestreaming.pdf target=_blank rel=noopener>PDF</a></div></div><div class=ml-3><a href=../zh/publication/chi23-dhh-livestreaming/><img src=../zh/publication/chi23-dhh-livestreaming/featured_hu66403fa46f96e7790dcc41af899c893f_7785539_150x0_resize_q75_h2_lanczos.webp height=50 width=150 alt="Sparkling Silence: Practices and Challenges of Livestreaming Among Deaf or Hard of Hearing Streamers" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/chi23-blv-robot-navigation/>"I am the follower, also the boss": Exploring Different Levels of Autonomy and Machine Forms of Guiding Robots for the Visually Impaired</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/yan-zhang/>Yan Zhang</a></span>, <span><a href=../zh/author/ziang-li/>Ziang Li</a></span>, <span><a href=../zh/author/haole-guo/>Haole Guo</a></span>, <span><a href=../zh/author/luyao-wang/>Luyao Wang</a></span>, <span><a href=../zh/author/qihe-chen/>Qihe Chen</a></span>, <span><a href=../zh/author/wenjie-jiang/>Wenjie Jiang</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span>, <span><a href=../zh/author/guyue-zhou/>Guyue Zhou</a></span>, <span><a href=../zh/author/jiangtao-gong/>Jiangtao Gong</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i></div><span class=article-date>二月 2023</span>
<span class=middot-divider></span>
<span class=pub-publication>CHI 2023</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/CHI2023_Navigation_Robot_Autonomy.pdf target=_blank rel=noopener>PDF</a></div></div><div class=ml-3><a href=../zh/publication/chi23-blv-robot-navigation/><img src=../zh/publication/chi23-blv-robot-navigation/featured_hu7dd70351c480c5148e6d50933c6c82c5_6142309_150x0_resize_q75_h2_lanczos.webp height=83 width=150 alt='"I am the follower, also the boss": Exploring Different Levels of Autonomy and Machine Forms of Guiding Robots for the Visually Impaired' loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/chi23-voice-hand-face/>Enabling Voice-Accompanying Hand-to-Face Gesture Recognition with Cross-Device Sensing</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/zisu-li/>Zisu Li</a></span>, <span><a href=../zh/author/chen-liang/>Chen Liang</a></span>, <span><a href=../zh/author/yuntao-wang/>Yuntao Wang</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i>, <span><a href=../zh/author/yue-qin/>Yue Qin</a></span>, <span><a href=../zh/author/chun-yu/>Chun Yu</a></span>, <span><a href=../zh/author/yukang-yan/>Yukang Yan</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span>, <span><a href=../zh/author/yuanchun-shi/>Yuanchun Shi</a></span></div><span class=article-date>二月 2023</span>
<span class=middot-divider></span>
<span class=pub-publication>CHI 2023</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/CHI23-voice-hand-gestures.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/zh/publication/chi23-voice-hand-face/cite.bib>引用</a></div></div><div class=ml-3><a href=../zh/publication/chi23-voice-hand-face/><img src=../zh/publication/chi23-voice-hand-face/featured_hub707d3d57145ddd61bb61ed9712d439d_375050_150x0_resize_q75_h2_lanczos.webp height=77 width=150 alt="Enabling Voice-Accompanying Hand-to-Face Gesture Recognition with Cross-Device Sensing" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/iwc2022-oa-vr-game-ta/>Older Adults’ Concurrent and Retrospective Think-Aloud Verbalizations for Identifying User Experience Problems of VR Games</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i>, <span><a href=../zh/author/vinita-tibdewal/>Vinita Tibdewal</a></span>, <span><a href=../zh/author/qiwen-zhao/>Qiwen Zhao</a></span>, <span><a href=../zh/author/lizhou-cao/>Lizhou Cao</a></span>, <span><a href=../zh/author/chao-peng/>Chao Peng</a></span>, <span><a href=../zh/author/runxuan-shu/>Runxuan Shu</a></span>, <span><a href=../zh/author/yujia-shan/>Yujia Shan</a></span></div><span class=article-date>十二月 2022</span>
<span class=middot-divider></span>
<span class=pub-publication>IwC 2022</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href="https://academic.oup.com/iwc/advance-article/doi/10.1093/iwc/iwac039/6967130?login=true" target=_blank rel=noopener>PDF</a></div></div><div class=ml-3><a href=../zh/publication/iwc2022-oa-vr-game-ta/><img src=../zh/publication/iwc2022-oa-vr-game-ta/featured_hu7a04c764ee55d5a23cb29d9fccfa075b_1261702_150x0_resize_q75_h2_lanczos.webp height=112 width=150 alt="Older Adults’ Concurrent and Retrospective Think-Aloud Verbalizations for Identifying User Experience Problems of VR Games" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/imwut22-oa-interactive-guidance/>Synapse: Interactive Guidance by Demonstration with Trial-and-Error Support for Older Adults to Use Smartphone Apps</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/xiaofu-jin/>Xiaofu Jin</a></span>, <span><a href=../zh/author/xiaozhu-hu/>Xiaozhu Hu</a></span>, <span><a href=../zh/author/xiaoying-wei/>Xiaoying Wei</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i></div><span class=article-date>十二月 2022</span>
<span class=middot-divider></span>
<span class=pub-publication>IMWUT 2022</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/IMWUT_OlderAdults_Trial_And_Error.pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/kSv-HOeTIkc target=_blank rel=noopener>视频</a></div></div><div class=ml-3><a href=../zh/publication/imwut22-oa-interactive-guidance/><img src=../zh/publication/imwut22-oa-interactive-guidance/featured_hucab56ae345f1dde599102718887d224d_1943476_150x0_resize_q75_h2_lanczos.webp height=28 width=150 alt="Synapse: Interactive Guidance by Demonstration with Trial-and-Error Support for Older Adults to Use Smartphone Apps" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/cscw22-typist/>Typist Experiment: an Investigation of Human-to-Human Dictation via Role-play to Inform Voice-based Text Authoring</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/can-liu/>Can Liu</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i>, <span><a href=../zh/author/siying-hu/>Siying Hu</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="student first author"></i>, <span><a href=../zh/author/li-feng/>Li Feng</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span></div><span class=article-date>十二月 2022</span>
<span class=middot-divider></span>
<span class=pub-publication>CSCW 2022</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://dl.acm.org/doi/pdf/10.1145/3555758 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/f9lO9tin4tw target=_blank rel=noopener>视频</a></div></div><div class=ml-3><a href=../zh/publication/cscw22-typist/><img src=../zh/publication/cscw22-typist/featured_hucac4c27c650346a6f5be2228389f5ea1_220965_150x0_resize_q75_h2_lanczos.webp height=74 width=150 alt="Typist Experiment: an Investigation of Human-to-Human Dictation via Role-play to Inform Voice-based Text Authoring" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/assets22-oa-banking/>"I Used To Carry A Wallet, Now I Just Need To Carry My Phone": Understanding Current Banking Practices and Challenges Among Older Adults in China</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/xiaofu-jin/>Xiaofu Jin</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i></div><span class=article-date>十二月 2022</span>
<span class=middot-divider></span>
<span class=pub-publication>ASSETS 2022</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/ASSETS22_Older_Adults_Banking.pdf target=_blank rel=noopener>PDF</a></div></div><div class=ml-3><a href=../zh/publication/assets22-oa-banking/><img src=../zh/publication/assets22-oa-banking/featured_huddae42340f0608af87bddd00dfad519f_581163_150x0_resize_q75_h2_lanczos.webp height=79 width=150 alt='"I Used To Carry A Wallet, Now I Just Need To Carry My Phone": Understanding Current Banking Practices and Challenges Among Older Adults in China' loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/chinesechi2022-olderadults-ai/>Understanding Older Adults' Perceptions and Challenges in Using AI-enabled Everyday Technologies</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/esha-shandilya/>Esha Shandilya</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i></div><span class=article-date>十二月 2022</span>
<span class=middot-divider></span>
<span class=pub-publication>Chinese CHI 2022</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/ChineseCHI22_OlderAdults_AI.pdf target=_blank rel=noopener>PDF</a></div></div><div class=ml-3><a href=../zh/publication/chinesechi2022-olderadults-ai/><img src=../zh/publication/chinesechi2022-olderadults-ai/featured_hub335d3ea1f75636366816e50c7809c44_195110_150x0_resize_q75_h2_lanczos.webp height=63 width=150 alt="Understanding Older Adults' Perceptions and Challenges in Using AI-enabled Everyday Technologies" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/ijhci-olderadults-covid-vis/>Understanding How Older Adults Comprehend COVID-19 Interactive Visualizations via Think-Aloud Protocol</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i>, <span><a href=../zh/author/yiwen-wang/>Yiwen Wang</a></span>, <span><a href=../zh/author/yuni-xie/>Yuni Xie</a></span>, <span><a href=../zh/author/franklin-li/>Franklin Li</a></span>, <span><a href=../zh/author/chunyang-chen/>Chunyang Chen</a></span></div><span class=article-date>十二月 2022</span>
<span class=middot-divider></span>
<span class=pub-publication>IJHCI</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/IJHCI-older-adults-visualizations.pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/IJHCI-older-adults-visualizations-appendix.pdf target=_blank rel=noopener>源文档</a></div></div><div class=ml-3><a href=../zh/publication/ijhci-olderadults-covid-vis/><img src=../zh/publication/ijhci-olderadults-covid-vis/featured_hu65fa16c210d01cc509c7b4a791933e6c_463709_150x0_resize_q75_h2_lanczos.webp height=124 width=150 alt="Understanding How Older Adults Comprehend COVID-19 Interactive Visualizations via Think-Aloud Protocol" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/chi22-ux-survey/>"Merging Results Is No Easy Task": An International Survey Study of Collaborative Data Analysis Practices Among UX Practitioners</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/emily-kuang/>Emily Kuang</a></span>, <span><a href=../zh/author/xiaofu-jin/>Xiaofu Jin</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i></div><span class=article-date>四月 2022</span>
<span class=middot-divider></span>
<span class=pub-publication>CHI 2022</span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/zh/publication/chi22-ux-survey/cite.bib>引用</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1145/3491102.3517647 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=../zh/publication/chi22-ux-survey/><img src=../zh/publication/chi22-ux-survey/featured_hu4039d55e0dc39e9ddd6d3b2c7c28dbc3_95433_150x0_resize_q75_h2_lanczos_3.webp height=69 width=150 alt='"Merging Results Is No Easy Task": An International Survey Study of Collaborative Data Analysis Practices Among UX Practitioners' loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/chi22-kuaidigui/>'I Shake The Package To Check If It's Mine': A Study of Package Fetching Practices and Challenges of Blind and Low Vision People in China</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/wentao-lei/>Wentao Lei</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i>, <span><a href=../zh/author/juliann-thang/>Juliann Thang</a></span></div><span class=article-date>三月 2022</span>
<span class=middot-divider></span>
<span class=pub-publication>CHI 2022</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/chi22_243_BLV_KuaiDiGui.pdf target=_blank rel=noopener>PDF</a></div></div><div class=ml-3><a href=../zh/publication/chi22-kuaidigui/><img src=../zh/publication/chi22-kuaidigui/featured_hu9189f72fef482c53a3d235abff599ee9_5712045_150x0_resize_q75_h2_lanczos.webp height=123 width=150 alt=" 'I Shake The Package To Check If It's Mine': A Study of Package Fetching Practices and Challenges of Blind and Low Vision People in China" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/chi22-userdefinedgestures/>'I Don't Want People to Look At Me Differently': Designing User-Defined Above-the-Neck Gestures for People with Upper Body Motor Impairments</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/xuan-zhao/>Xuan Zhao</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i>, <span><a href=../zh/author/teng-han/>Teng Han</a></span></div><span class=article-date>三月 2022</span>
<span class=middot-divider></span>
<span class=pub-publication>CHI 2022</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/chi22_243_BLV_KuaiDiGui.pdf target=_blank rel=noopener>PDF</a></div></div><div class=ml-3><a href=../zh/publication/chi22-userdefinedgestures/><img src=../zh/publication/chi22-userdefinedgestures/featured_hud01615fd1e109ad5e9bfd88ce28472e6_744233_150x0_resize_q75_h2_lanczos.webp height=170 width=150 alt=" 'I Don't Want People to Look At Me Differently': Designing User-Defined Above-the-Neck Gestures for People with Upper Body Motor Impairments" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/cacm-eyelidgestures/>Eyelid Gestures for People with Motor Impairments</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i>, <span><a href=../zh/author/zhen-li/>Zhen Li</a></span>, <span><a href=../zh/author/franklin-mingzhe-li/>Franklin Mingzhe Li</a></span></div><span class=article-date>三月 2022</span>
<span class=middot-divider></span>
<span class=pub-publication>CACM 2022</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://cacm.acm.org/magazines/2022/1/257451-eyelid-gestures-for-people-with-motor-impairments/pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/mingming-fan/EyelidGesturesDetection target=_blank rel=noopener>代码</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://cacm.acm.org/magazines/2022/1/257452-technical-perspective-eyelid-gestures-enhance-mobile-interaction/abstract target=_blank rel=noopener>项目</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=GgpW4tmvdM0" target=_blank rel=noopener>视频</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://cacm.acm.org/magazines/2022/1/257451-eyelid-gestures-for-people-with-motor-impairments/fulltext target=_blank rel=noopener>源文档</a></div></div><div class=ml-3><a href=../zh/publication/cacm-eyelidgestures/><img src=../zh/publication/cacm-eyelidgestures/featured_hu37f591076f984926bf945660cf87cb66_153401_150x0_resize_q75_h2_lanczos.webp height=150 width=150 alt="Eyelid Gestures for People with Motor Impairments" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/coux/>CoUX: Collaborative Visual Analysis of Think-Aloud Usability Test Videos for Digital Interfaces</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/ehsan-jahangirzadeh-soure/>Ehsan Jahangirzadeh Soure</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal Contribution"></i>, <span><a href=../zh/author/emily-kuang/>Emily Kuang</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal Contribution"></i>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i>, <span><a href=../zh/author/jian-zhao/>Jian Zhao</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding author"></i></div><span class=article-date>十二月 2021</span>
<span class=middot-divider></span>
<span class=pub-publication>VIS 2021</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/coux-vis21.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/zh/publication/coux/cite.bib>引用</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/WatVis/CoUX target=_blank rel=noopener>代码</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=uaSl0x4c93Y" target=_blank rel=noopener>视频</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1109/TVCG.2021.3114822 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=../zh/publication/coux/><img src=../zh/publication/coux/featured_hu5aa6ab34d05d6616d78c82fee54391f1_768341_150x0_resize_q75_h2_lanczos_3.webp height=82 width=150 alt="CoUX: Collaborative Visual Analysis of Think-Aloud Usability Test Videos for Digital Interfaces" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/oa-ta/>Older Adults' Think-Aloud Verbalizations and Speech Features for Identifying User Experience Problems</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span>, <span><a href=../zh/author/qiwen-zhao/>Qiwen Zhao</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="first student author"></i>, <span><a href=../zh/author/vinita-tibdewal/>Vinita Tibdewal</a></span></div><span class=article-date>十二月 2021</span>
<span class=middot-divider></span>
<span class=pub-publication>CHI 2021</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/CHI21_OlderAdults_ThinkAloud_UXProblems.pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=OkqStiGulbY" target=_blank rel=noopener>视频</a></div></div><div class=ml-3><a href=../zh/publication/oa-ta/><img src=../zh/publication/oa-ta/featured_huc5b2596daae37e4fdf3fb1aed1ae36ef_1083293_150x0_resize_q75_h2_lanczos.webp height=66 width=150 alt="Older Adults' Think-Aloud Verbalizations and Speech Features for Identifying User Experience Problems" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/chartseer/>ChartSeer: Interactive Steering Exploratory Visual Analysis with Machine Intelligence</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/jian-zhao/>Jian Zhao</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span>, <span><a href=../zh/author/mi-feng/>Mi Feng</a></span></div><span class=article-date>五月 2021</span>
<span class=middot-divider></span>
<span class=pub-publication>TVCG (VIS 2021)</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/chartseer_tvcg.pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=w5K1U6f1Oro" target=_blank rel=noopener>视频</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1109/TVCG.2020.3018724 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=../zh/publication/chartseer/><img src=../zh/publication/chartseer/featured_hu51898de3fd3f3dcd85fe409605814c5e_1708443_150x0_resize_q75_h2_lanczos.webp height=93 width=150 alt="ChartSeer: Interactive Steering Exploratory Visual Analysis with Machine Intelligence" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/eyelidgestures4assets/>Eyelid Gestures on Mobile Devices for People with Motor Impairments</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="equal contribution"></i>, <span><a href=../zh/author/zhen-li/>Zhen Li</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="equal contribution"></i>, <span><a href=../zh/author/franklin-mingzhe-li/>Franklin Mingzhe Li</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="equal contribution"></i></div><span class=article-date>十一月 2020</span>
<span class=middot-divider></span>
<span class=pub-publication>ASSETS 2020</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/ASSETS_2020_Fan.pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/mingming-fan/EyelidGesturesDetection target=_blank rel=noopener>代码</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://cacm.acm.org/magazines/2022/1/257452-technical-perspective-eyelid-gestures-enhance-mobile-interaction/abstract target=_blank rel=noopener>项目</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=hocUdFlgX5A" target=_blank rel=noopener>视频</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/mingming-fan/EyelidGesturesDetection/releases target=_blank rel=noopener>源文档</a></div></div><div class=ml-3><a href=../zh/publication/eyelidgestures4assets/><img src=../zh/publication/eyelidgestures4assets/featured_hu16917b679f115b07e8fd438e20cd64cf_105865_150x0_resize_q75_h2_lanczos.webp height=61 width=150 alt="Eyelid Gestures on Mobile Devices for People with Motor Impairments" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/uxproblemsdetection/>Automatic Detection of Usability Problem Encounters in Think-Aloud Sessions</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span>, <span><a href=../zh/author/yue-li/>Yue Li</a></span>, <span><a href=../zh/author/khai-n.-truong/>Khai N. Truong</a></span></div><span class=article-date>五月 2020</span>
<span class=middot-divider></span>
<span class=pub-publication>TiiS 2020</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/TiiS2020-Fan.pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1145/3491102.3517647 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=../zh/publication/uxproblemsdetection/><img src=../zh/publication/uxproblemsdetection/featured_hub8d52aa5372c63e77d4d9bef65ae253e_16155_150x0_resize_q75_h2_lanczos.webp height=63 width=150 alt="Automatic Detection of Usability Problem Encounters in Think-Aloud Sessions" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/vista/>VisTA: Integrating Machine Intelligence with Visualization to Support the Investigation of Think-Aloud Sessions</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span>, <span><a href=../zh/author/ke-wu/>Ke Wu</a></span>, <span><a href=../zh/author/jian-zhao/>Jian Zhao</a></span>, <span><a href=../zh/author/yue-li/>Yue Li</a></span>, <span><a href=../zh/author/winter-wei/>Winter Wei</a></span>, <span><a href=../zh/author/khai-n.-truong/>Khai N. Truong</a></span></div><span class=article-date>四月 2019</span>
<span class=middot-divider></span>
<span class=pub-publication>TVCG (VIS 2019)</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/VisTA.pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=YHpfBqm1Aaw" target=_blank rel=noopener>视频</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1109/TVCG.2019.2934797 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=../zh/publication/vista/><img src=../zh/publication/vista/featured_hu94650d6457ed202eb28fa4c216d9947d_1136558_150x0_resize_q75_h2_lanczos.webp height=68 width=150 alt="VisTA: Integrating Machine Intelligence with Visualization to Support the Investigation of Think-Aloud Sessions" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/inkplanner/>InkPlanner: Supporting Prewriting via Intelligent Visual Diagramming</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/zhicong-lu/>Zhicong Lu</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span>, <span><a href=../zh/author/yun-wang/>Yun Wang</a></span>, <span><a href=../zh/author/jian-zhao/>Jian Zhao</a></span>, <span><a href=../zh/author/michelle-annett/>Michelle Annett</a></span>, <span><a href=../zh/author/daniel-wigdor/>Daniel Wigdor</a></span></div><span class=article-date>十二月 2018</span>
<span class=middot-divider></span>
<span class=pub-publication>TVCG (VIS 2018)</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/InkPlanner_TVCG.pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=vzVOdtCP5LM" target=_blank rel=noopener>视频</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1145/3491102.3517647 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=../zh/publication/inkplanner/><img src=../zh/publication/inkplanner/featured_hudbd6c8bfdf01566ce54eaf958a0b0978_506254_150x0_resize_q75_h2_lanczos.webp height=94 width=150 alt="InkPlanner: Supporting Prewriting via Intelligent Visual Diagramming" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/seniorguidelines/>Guidelines for Creating Senior-Friendly Product Instructions</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span>, <span><a href=../zh/author/khai-n.-truong/>Khai N. Truong</a></span></div><span class=article-date>四月 2018</span>
<span class=middot-divider></span>
<span class=pub-publication>TACCESS (ASSETS 2018)</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/TACCESS-2018-Fan.pdf target=_blank rel=noopener>PDF</a></div></div><div class=ml-3><a href=../zh/publication/seniorguidelines/><img src=../zh/publication/seniorguidelines/featured_huf46122220513721019857947253c18bc_3142509_150x0_resize_q75_h2_lanczos.webp height=93 width=150 alt="Guidelines for Creating Senior-Friendly Product Instructions" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=../zh/publication/braillesketch/>BrailleSketch: A Gesture-based Text Entry Method for People with Visual Impairments</a></div><div class="stream-meta article-metadata"><div class=article-metadata><div><span><a href=../zh/author/franklin-li/>Franklin Li</a></span>, <span><a href=../zh/author/mingming-fan/>Mingming Fan</a></span>, <span><a href=../zh/author/khai-n.-truong/>Khai N. Truong</a></span></div><span class=article-date>八月 2017</span>
<span class=middot-divider></span>
<span class=pub-publication>ASSETS 2017</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.mingmingfan.com/papers/BrailleSketch-ASSETS-2017.pdf target=_blank rel=noopener>PDF</a></div></div><div class=ml-3><a href=../zh/publication/braillesketch/><img src=../zh/publication/braillesketch/featured_hu9f3a4d2f43c4f68e2627d7f2e1d6912a_278010_150x0_resize_q75_h2_lanczos.webp height=128 width=150 alt="BrailleSketch: A Gesture-based Text Entry Method for People with Visual Impairments" loading=lazy></a></div></div></div></div></div></section></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2023 APEX Group. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>由<a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a>支持发布——免费<a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>开源</a>网站，为创作者赋能。</p></footer></div></div><script src=../js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":false}</script><script src=../zh/js/wowchemy.min.b031b58d2daeebaaee5c315db61367f3.js></script>
<script src=../js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>引用</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> 复制</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> 下载</a><div id=modal-error></div></div></div></div></div><script src=../js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>
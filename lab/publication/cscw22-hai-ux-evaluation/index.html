<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=stylesheet href=../../css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=../../css/wowchemy.b9231f75dcc97a371ce6141b4d2aadaf.css><link rel=stylesheet href=../../css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=../../css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Mingming Fan"><meta name=description content="Analyzing usability test videos is arduous. Although recent research showed the promise of AI in assisting with such tasks, it remains largely unknown how AI should be designed to facilitate effective collaboration between user experience (UX) evaluators and AI. Inspired by the concepts of agency and work context in human and AI collaboration literature, we studied two corresponding design factors for AI-assisted UX evaluation: explanations and synchronization. Explanations allow AI to further inform humans how it identifies UX problems from a usability test session; synchronization refers to the two ways humans and AI collaborate: synchronously and asynchronously. We iteratively designed a tool—AI Assistant—with four versions of UIs corresponding to the two levels of explanations (with/without) and synchronization (sync/async). By adopting a hybrid wizard-of-oz approach to simulating an AI with reasonable performance, we conducted a mixed-method study with 24 UX evaluators identifying UX problems from usability test videos using AI Assistant. Our quantitative and qualitative results show that AI with explanations, regardless of being presented synchronously or asynchronously, provided better support for UX evaluators’ analysis and was perceived more positively; when without explanations, synchronous AI better improved UX evaluators’ performance and engagement compared to the asynchronous AI. Lastly, we present the design implications for AI-assisted UX evaluation and facilitating more effective human-AI collaboration."><link rel=alternate hreflang=zh href=../../zh/publication/cscw22-hai-ux-evaluation/><link rel=alternate hreflang=en-us href=../../publication/cscw22-hai-ux-evaluation/><link rel=canonical href=../../publication/cscw22-hai-ux-evaluation/><link rel=manifest href=../../manifest.webmanifest><link rel=icon type=image/png href=../../media/icon_hu9a55cf1972a19f5af2e1cfae94af68a2_11598_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=../../media/icon_hu9a55cf1972a19f5af2e1cfae94af68a2_11598_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@wowchemy"><meta property="twitter:creator" content="@wowchemy"><meta property="twitter:image" content="/publication/cscw22-hai-ux-evaluation/featured.jpg"><meta property="og:site_name" content="APEX, HKUST(GZ) & HKUST"><meta property="og:url" content="/publication/cscw22-hai-ux-evaluation/"><meta property="og:title" content="Human-AI Collaboration for UX Evaluation: Effects of Explanation and Synchronization | APEX, HKUST(GZ) & HKUST"><meta property="og:description" content="Analyzing usability test videos is arduous. Although recent research showed the promise of AI in assisting with such tasks, it remains largely unknown how AI should be designed to facilitate effective collaboration between user experience (UX) evaluators and AI. Inspired by the concepts of agency and work context in human and AI collaboration literature, we studied two corresponding design factors for AI-assisted UX evaluation: explanations and synchronization. Explanations allow AI to further inform humans how it identifies UX problems from a usability test session; synchronization refers to the two ways humans and AI collaborate: synchronously and asynchronously. We iteratively designed a tool—AI Assistant—with four versions of UIs corresponding to the two levels of explanations (with/without) and synchronization (sync/async). By adopting a hybrid wizard-of-oz approach to simulating an AI with reasonable performance, we conducted a mixed-method study with 24 UX evaluators identifying UX problems from usability test videos using AI Assistant. Our quantitative and qualitative results show that AI with explanations, regardless of being presented synchronously or asynchronously, provided better support for UX evaluators’ analysis and was perceived more positively; when without explanations, synchronous AI better improved UX evaluators’ performance and engagement compared to the asynchronous AI. Lastly, we present the design implications for AI-assisted UX evaluation and facilitating more effective human-AI collaboration."><meta property="og:image" content="/publication/cscw22-hai-ux-evaluation/featured.jpg"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2022-12-23T00:00:00+00:00"><meta property="article:modified_time" content="2022-12-23T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"/publication/cscw22-hai-ux-evaluation/"},"headline":"Human-AI Collaboration for UX Evaluation: Effects of Explanation and Synchronization","image":["/publication/cscw22-hai-ux-evaluation/featured.jpg"],"datePublished":"2022-12-23T00:00:00Z","dateModified":"2022-12-23T00:00:00Z","author":{"@type":"Person","name":"Mingming Fan"},"publisher":{"@type":"Organization","name":"APEX, HKUST(GZ) \u0026 HKUST","logo":{"@type":"ImageObject","url":"/media/logo_hub0d66fecfb75d04d26dd973adb7e184d_88470_192x192_fit_lanczos_3.png"}},"description":"Analyzing usability test videos is arduous. Although recent research showed the promise of AI in assisting with such tasks, it remains largely unknown how AI should be designed to facilitate effective collaboration between user experience (UX) evaluators and AI. Inspired by the concepts of agency and work context in human and AI collaboration literature, we studied two corresponding design factors for AI-assisted UX evaluation: explanations and synchronization. Explanations allow AI to further inform humans how it identifies UX problems from a usability test session; synchronization refers to the two ways humans and AI collaborate: synchronously and asynchronously. We iteratively designed a tool—AI Assistant—with four versions of UIs corresponding to the two levels of explanations (with/without) and synchronization (sync/async). By adopting a hybrid wizard-of-oz approach to simulating an AI with reasonable performance, we conducted a mixed-method study with 24 UX evaluators identifying UX problems from usability test videos using AI Assistant. Our quantitative and qualitative results show that AI with explanations, regardless of being presented synchronously or asynchronously, provided better support for UX evaluators’ analysis and was perceived more positively; when without explanations, synchronous AI better improved UX evaluators’ performance and engagement compared to the asynchronous AI. Lastly, we present the design implications for AI-assisted UX evaluation and facilitating more effective human-AI collaboration."}</script><title>Human-AI Collaboration for UX Evaluation: Effects of Explanation and Synchronization | APEX, HKUST(GZ) & HKUST</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=03458b8a5b5ae4c9437527c77b145805><script src=../../js/wowchemy-init.min.fe8634e7d00f14d07fb33caf14cc8e55.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=../../><img src=../../media/logo_hub0d66fecfb75d04d26dd973adb7e184d_88470_0x70_resize_lanczos_3.png alt="APEX, HKUST(GZ) & HKUST"></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=../../><img src=../../media/logo_hub0d66fecfb75d04d26dd973adb7e184d_88470_0x70_resize_lanczos_3.png alt="APEX, HKUST(GZ) & HKUST"></a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=../../><span>Home</span></a></li><li class=nav-item><a class=nav-link href=../../people><span>People</span></a></li><li class=nav-item><a class=nav-link href=../../publication><span>Publications</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown i18n-dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true aria-label=Languages><i class="fas fa-globe mr-1" aria-hidden=true></i><span class="d-none d-lg-inline">English</span></a><div class=dropdown-menu><div class="dropdown-item dropdown-item-active"><span>English</span></div><a class=dropdown-item href=../../zh/publication/cscw22-hai-ux-evaluation/><span>中文 (简体)</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>Human-AI Collaboration for UX Evaluation: Effects of Explanation and Synchronization</h1><div class=article-metadata><div><span><a href=../../author/mingming-fan/>Mingming Fan</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Corresponding Author"></i>, <span><a href=../../author/xianyou-yang/>Xianyou Yang</a></span>, <span><a href=../../author/tsz-tung-yu/>Tsz Tung Yu</a></span>, <span><a href=../../author/vera-q.-liao/>Vera Q. Liao</a></span>, <span><a href=../../author/jian-zhao/>Jian Zhao</a></span></div><span class=article-date>December 2022</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=https://www.mingmingfan.com/papers/haicollaboration-cscw2022.pdf target=_blank rel=noopener>PDF</a></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:442px><div style=position:relative><img src=../../publication/cscw22-hai-ux-evaluation/featured_hu0d5b524f76b3552493e940be452e707d_137076_720x2500_fit_q75_h2_lanczos.webp width=720 height=442 alt class=featured-image></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>Analyzing usability test videos is arduous. Although recent research showed the promise of AI in assisting with such tasks, it remains largely unknown how AI should be designed to facilitate effective collaboration between user experience (UX) evaluators and AI. Inspired by the concepts of agency and work context in human and AI collaboration literature, we studied two corresponding design factors for AI-assisted UX evaluation: explanations and synchronization. Explanations allow AI to further inform humans how it identifies UX problems from a usability test session; synchronization refers to the two ways humans and AI collaborate: synchronously and asynchronously. We iteratively designed a tool—AI Assistant—with four versions of UIs corresponding to the two levels of explanations (with/without) and synchronization (sync/async). By adopting a hybrid wizard-of-oz approach to simulating an AI with reasonable performance, we conducted a mixed-method study with 24 UX evaluators identifying UX problems from usability test videos using AI Assistant. Our quantitative and qualitative results show that AI with explanations, regardless of being presented synchronously or asynchronously, provided better support for UX evaluators’ analysis and was perceived more positively; when without explanations, synchronous AI better improved UX evaluators’ performance and engagement compared to the asynchronous AI. Lastly, we present the design implications for AI-assisted UX evaluation and facilitating more effective human-AI collaboration.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">All Topics</div><div class="col-12 col-md-9"><a href=../../publication/#3>Human-AI Collaboration</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Publication</div><div class="col-12 col-md-9">Proceedings of the ACM on Human-Computer Interaction (PACM HCI)</div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=../../tag/human-ai-collaboration/>Human-AI collaboration</a>
<a class="badge badge-light" href=../../tag/user-experience-ux/>user experience (UX)</a>
<a class="badge badge-light" href=../../tag/ai-assisted-ux-evaluation/>AI-assisted UX evaluation</a>
<a class="badge badge-light" href=../../tag/explainable-ai/>explainable AI</a>
<a class="badge badge-light" href=../../tag/intelligent-user-interface-ui-design/>intelligent user interface (UI) design</a>
<a class="badge badge-light" href=../../tag/synchronization/>synchronization</a>
<a class="badge badge-light" href=../../tag/explanation/>explanation</a>
<a class="badge badge-light" href=../../tag/think-aloud-usability-test/>think-aloud usability test</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=%2Fpublication%2Fcscw22-hai-ux-evaluation%2F&amp;text=Human-AI+Collaboration+for+UX+Evaluation%3A+Effects+of+Explanation+and+Synchronization" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=%2Fpublication%2Fcscw22-hai-ux-evaluation%2F&amp;t=Human-AI+Collaboration+for+UX+Evaluation%3A+Effects+of+Explanation+and+Synchronization" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Human-AI%20Collaboration%20for%20UX%20Evaluation%3A%20Effects%20of%20Explanation%20and%20Synchronization&amp;body=%2Fpublication%2Fcscw22-hai-ux-evaluation%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=%2Fpublication%2Fcscw22-hai-ux-evaluation%2F&amp;title=Human-AI+Collaboration+for+UX+Evaluation%3A+Effects+of+Explanation+and+Synchronization" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Human-AI+Collaboration+for+UX+Evaluation%3A+Effects+of+Explanation+and+Synchronization%20%2Fpublication%2Fcscw22-hai-ux-evaluation%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=%2Fpublication%2Fcscw22-hai-ux-evaluation%2F&amp;title=Human-AI+Collaboration+for+UX+Evaluation%3A+Effects+of+Explanation+and+Synchronization" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2023 APEX Group. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=../../js/vendor-bundle.min.b4708d4364577c16ab7001b265a063a4.js></script><script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":true}</script><script src=../../js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script><script src=../../en/js/wowchemy.min.6ab16275cbca742a586c1726e3d94093.js></script><script src=../../js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=../../js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>